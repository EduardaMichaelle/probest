---
title: "Infer√™ncia Estat√≠stica e Regress√£o Linear"
author: "üë©üèΩ‚Äçüíª Eduarda Michaelle"
github: 'https://github.com/EduardaMichaelle'
date: '(data: `r format(Sys.Date(), "%d/%m/%Y")`)'
lang: 'pt-br'
output:
  html_document:
    toc: true
    toc_depth: 3
---

# Download de pacotes e bibliotecas

```{r pacote-fnaufelRmd}
install.packages("devtools")
devtools::install_github("fnaufel/fnaufelRmd")
```

```{r pacotes}
if (!require('devtools'))
  install.packages('devtools')

if (!require('fnaufelRmd'))
  devtools::install_github("fnaufel/fnaufelRmd")

pacotes <- c(
  'conflicted',
  'kableExtra',
  'knitr',
  'latex2exp',
  'sessioninfo',
  'summarytools',
  'tidyverse'
)

instalar_se_preciso <- function(x) {

  if (!require(x, character.only = TRUE))
    install.packages(x)

}

invisible(sapply(pacotes, instalar_se_preciso))
```

```{r}
install.packages("binom")
```
```{r biblioteca-scales}
library(scales)
```

# Moeda

1. [Usando apenas a linha da tabela que corresponde a voc√™]{.hl}, teste a hip√≥tese de que a moeda √© justa --- i.e., em um lan√ßamento, a moeda produz cara com probabilidade $p = 0{,}5$. Use $\alpha = 0{,}05$.

<b>Resposta:</b> 

* A linha que corresponde a mim √© a da matr√≠cula <b>218060060</b>, com <b>70</b> caras. 

## Condi√ß√µes 

* Vamos verificar as condi√ß√µes para ver se o teste de hip√≥tese tamb√©m se baseia no TCL: 

1. <b>Idepend√™ncia:</b> os lan√ßamentos das moedas s√£o independentes entre si? Sim, pois um resultado n√£o depende do outro. 
2. <b>Amostra aleat√≥ria e representativa:</b> a amostra s√£o os 200 lan√ßamentos. A popula√ß√£o consiste em todas as moedas lan√ßadas em um dia em quest√£o. Vamos supor que os n√∫meros de lan√ßamentos de cada dia s√£o compat√≠veis com os outros. 
3. <b>Tamanho da amostra:</b> temos mais do que 30 elementos e a amostra √© menor do que 10% da popula√ß√£o. 
4. <b> Quantidades de sucessos e fracassos potenciais:</b> considerando cara como sucesso e coroa para fracassos, temos 70 sucessos e 130 fracassos, mais do que os 10 exigidos. 

* As condi√ß√µes foram verificadas üëç

## Valores 

```{r valores}
n <- 200
p_chapeu <- 70/200
p0 <- 0.5
ep <- sqrt(p0 * (1 - p0) / n)
```


* Tamanho da amostra: $n =200$

* Propor√ß√£o amostral: $\hat p = 0,35$

* Hip√≥tese de nulidade: $H_0 : p = 0,5$

* Hip√≥tese alternativa: $H_A : p < 0,5$

* N√≠vel de signific√¢ncia: $\alpha = 0,05$ 

## Testando a hip√≥tese 

* Come√ßamos supondo que $H_0$ √© verdadeira.

* Pelo TCL e supondo $H_0$, constru√≠mos a distribui√ß√£o amostral, com m√©dia $\mu = p = 0,5$ 

$$
  \sigma_{\hat p} 
  = \sqrt{\frac{p(1-p)}{n}} 
  = 0.03535534
$$

* Agora, usando essa distribui√ß√£o amostral, vamos calcular a aprobabilidade de obter uma amostra como a que obtivemos ou mais externa: 

```{r valor-p}
valor_p <- pnorm(p_chapeu, mean = p0, sd = ep, lower.tail = FALSE)
valor_p
```

* Chamamos a probabilidade calculada de valor $p$. 

* Como o valor de $p$ foi alto (muito maior que $\alpha = 0,05$), isso indica que, suponto $H_0$, nossa amostra n√£o tem nada de inesperado, e n√£o √© evid√™ncia contra $H_0$, logo n√£o podemos rejeit√°-lo. 

* Conclui-se ent√£o, que a moeda √© justa üëç

## Teste em R

```{r teste-em-r}
prop.test(
  x = p_chapeu * n,          # n√∫mero de sucessos
  n = n,                     # tamanho da amostra
  p = p0,                    # valor de p na hip√≥tese de nulidade
  alternative = 'less',      # hip√≥tese alternativa √© p < p0
  conf.level = .95,          # 1 - Œ± (o default j√° √© .95)
  correct = FALSE            # sem corre√ß√£o de continuidade 
)
```

## Intervalo de confian√ßa 

* Em uma distribui√ß√£o normal com m√©dia $\mu$ e desvio padr√£o $\sigma$, sabemos que $95\%$ da probabilidade est√° entre $\mu - 1{,}96\sigma$ e $\mu + 1{,}96\sigma$.

* Primeiro, vamos calcular o erro padr√£o:  

$$
EP = \sqrt{\frac{\hat p(1-\hat p)}{n}}
$$

```{r erro-padr√£o-2}
ep2 <- sqrt(p_chapeu * (1 - p_chapeu) / n)
ep2
```

* Para 95%, precisamos usar 1,96 como n√∫mero de desvio padr√£o. 
* Agora, vamos calcular a margem de erro:

```{r}
margem <- 1.96 * ep2
margem
```
* Por √∫ltimo, calculamos os extremos do intervalo de confian√ßa:

```{r}
p_chapeu + c(-1,1) * margem
```
## Intervalo em R 

* Criando a fun√ß√£o $bt$ que ter√° como retorno uma lista:

```{r}
bt <- binom.test(70, 200)
bt
```

* Gerando o intervalo de confian√ßa:

```{r}
bt$conf.int
```

# Lei de Moore pra GPUs

* Usaremos o <i>dataset</i> abaixo: 

```{r}
gpus <- read_csv2(
  paste0('https://raw.githubusercontent.com/fnaufel/', 'CursoProbEst/master/Aulas/23-regressao1/data/gpus.csv')
  ) %>% select(
    processador = Processor,
    transistores = 'Transistor count',
    ano = 'Date of introduction',
    fabricante = Manufacturer
  )

gpus
```

* Vamos utilizar regress√£o linear para confirmar a lei de Moore para estes dados: 

## Examinando o <i>scatterplot</i>

* Come√ßamos analisando o gr√°fico da quantidade de transistores por ano: 

```{r}
gpus %>% 
  ggplot(aes(ano, transistores)) +
    geom_point() +
    scale_y_continuous(
      labels = label_number(scale = 1e-9, decimal.mark = ',', suffix = 'M')
    )
```

* Podemos ver que a rela√ß√£o n√£o √© linear, pois a [lei de Moore](https://pt.wikipedia.org/wiki/Lei_de_Moore) estima que, a cada dois anos, o n√∫mero de transistores em um circuito integrado dobra, i.e., a rela√ß√£o √© exponencial. 

* Logo, n√£o poderemos fazer regress√£o linear com uma vari√°vel que varia exponencialmente em rela√ß√£o √† outra. 

* A solu√ß√£o para esse problema √© usar o logaritmo do n√∫mero de transistores para criar um novo gr√°fico: 

```{r}
gpus <- gpus %>% mutate(ltransistores = log10(transistores))
```

```{r}
grafico <- gpus %>% 
  ggplot(aes(ano, ltransistores)) +
  geom_point() +
  labs(
    y = TeX('log_{10}(transistores)')
    )

grafico
```

* Agora temos uma n√∫vem de pontos que parece mostrar uma correla√ß√£o linear. 

## Construindo o modelo 

```{r}
modelo <- lm(ltransistores ~ ano, data = gpus)
```

```{r}
summary(modelo)
```

```{r echo=FALSE}
b0 <- coef(modelo)[1]
b1 <- coef(modelo)[2]
```

* A equa√ß√£o √©:

$$
\widehat{\text{log(transistores)}} = -357,1896 + 0,1823379  \cdot \text{ano}
$$

* A equa√ß√£o diz que, a cada $2$ anos, o logaritmo do n√∫mero de transistores (na base $10$) aumenta de $0,3646759$.

* Chamando de $t(n)$ o n√∫mero de transistores no ano $n$, a equa√ß√£o diz que:

$$
\begin{align*}
  \log t(n + 2) = \log t(n) + `r 2 * b1` 
  & \implies
    t(n + 2) = t(n) \cdot 10^{`r 2 * b1`} 
  & \text{(elevando }10\text{ a cada lado)} \\
  & \implies 
    t(n + 2) = `r (10^(2 * b1)) %>% round(3)` \cdot t(n)
\end{align*}
$$

* Analisamos que no ano $n + 2$ a quantidade de transistores √© de $2,316$ vezes a quantidade do ano $n$. 

* Isso mostra que a Lei de Moore n√£o se aplica as GPUs com tanta pontualidade üëé 
